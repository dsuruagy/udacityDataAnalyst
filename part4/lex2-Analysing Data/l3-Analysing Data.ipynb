{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using group\n",
    "\n",
    "The tweets in our twitter collection have a field called \"source\". This field describes the application\n",
    "that was used to create the tweet. Following the examples for using the $group operator, your task is \n",
    "to modify the 'make-pipeline' function to identify most used applications for creating tweets. \n",
    "As a check on your query, 'web' is listed as the most frequently used application.\n",
    "'Ubertwitter' is the second most used. The number of counts should be stored in a field named 'count'\n",
    "(see the assertion at the end of the script).\n",
    "\n",
    "Please modify only the 'make_pipeline' function so that it creates and returns an aggregation pipeline\n",
    "that can be passed to the MongoDB aggregate function. As in our examples in this lesson, the aggregation \n",
    "pipeline should be a list of one or more dictionary objects. \n",
    "Please review the lesson examples if you are unsure of the syntax.\n",
    "\n",
    "Your code will be run against a MongoDB instance that we have provided. \n",
    "If you want to run this code locally on your machine, you have to install MongoDB, \n",
    "download and insert the dataset.\n",
    "For instructions related to MongoDB setup and datasets please see Course Materials.\n",
    "\n",
    "Please note that the dataset you are using here is a smaller version of the twitter dataset \n",
    "used in examples in this lesson. \n",
    "If you attempt some of the same queries that we looked at in the lesson examples,\n",
    "your results will be different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'_id': u'web', u'count': 23136}\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-3ba239c5fc0a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mpprint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mpprint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34mu'count'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m868\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mu'_id'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34mu'web'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def get_db(db_name):\n",
    "    from pymongo import MongoClient\n",
    "    client = MongoClient('localhost:27017')\n",
    "    db = client[db_name]\n",
    "    return db\n",
    "\n",
    "def make_pipeline():\n",
    "    # complete the aggregation pipeline\n",
    "    pipeline = [{'$group' : {'_id' : '$source', 'count' : {'$sum' : 1}}},\n",
    "                {'$sort' : {'count' : -1}}]\n",
    "    return pipeline\n",
    "\n",
    "def tweet_sources(db, pipeline):\n",
    "    return [doc for doc in db.tweets.aggregate(pipeline)]\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    db = get_db('twitter')\n",
    "    \n",
    "    pipeline = make_pipeline()\n",
    "    result = tweet_sources(db, pipeline)\n",
    "    import pprint\n",
    "    pprint.pprint(result[0])\n",
    "    assert result[0] == {u'count': 868, u'_id': u'web'}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using match and project\n",
    "\n",
    "Write an aggregation query to answer this question:\n",
    "\n",
    "Of the users in the \"Brasilia\" timezone who have tweeted 100 times or more,\n",
    "who has the largest number of followers?\n",
    "\n",
    "The following hints will help you solve this problem:\n",
    "- Time zone is found in the \"time_zone\" field of the user object in each tweet.\n",
    "- The number of tweets for each user is found in the \"statuses_count\" field.\n",
    "  To access these fields you will need to use dot notation (from Lesson 4)\n",
    "- Your aggregation query should return something like the following:\n",
    "\n",
    "`{u'ok': 1.0,\n",
    " u'result': [{u'_id': ObjectId('52fd2490bac3fa1975477702'),\n",
    "                  u'followers': 2597,\n",
    "                  u'screen_name': u'marbles',\n",
    "                  u'tweets': 12334}]}`\n",
    "                  \n",
    "Note that you will need to create the fields 'followers', 'screen_name' and 'tweets'.\n",
    "\n",
    "Please modify only the 'make_pipeline' function so that it creates and returns an aggregation \n",
    "pipeline that can be passed to the MongoDB aggregate function. As in our examples in this lesson,\n",
    "the aggregation pipeline should be a list of one or more dictionary objects. \n",
    "Please review the lesson examples if you are unsure of the syntax.\n",
    "\n",
    "Your code will be run against a MongoDB instance that we have provided. If you want to run this code\n",
    "locally on your machine, you have to install MongoDB, download and insert the dataset.\n",
    "For instructions related to MongoDB setup and datasets please see Course Materials.\n",
    "\n",
    "Please note that the dataset you are using here is a smaller version of the twitter dataset used \n",
    "in examples in this lesson. If you attempt some of the same queries that we looked at in the lesson \n",
    "examples, your results will be different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{u'_id': ObjectId('59373bdc776f4003f7d5b141'),\n",
      "  u'followers': 259760,\n",
      "  u'screen_name': u'otaviomesquita',\n",
      "  u'tweets': 10997}]\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-70fc6a413cba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mpprint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"followers\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m17209\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def get_db(db_name):\n",
    "    from pymongo import MongoClient\n",
    "    client = MongoClient('localhost:27017')\n",
    "    db = client[db_name]\n",
    "    return db\n",
    "\n",
    "def make_pipeline():\n",
    "    # complete the aggregation pipeline\n",
    "    pipeline = [{'$match' : {'user.time_zone' : 'Brasilia', 'user.statuses_count' : {'$gt' : 100}}},\n",
    "                {'$project' : {'followers' : '$user.followers_count', 'screen_name' : '$user.screen_name',\n",
    "                                'tweets' : '$user.statuses_count'}},\n",
    "                {'$sort' : {'followers' : -1}}, \n",
    "                {'$limit' : 1}]\n",
    "    return pipeline\n",
    "\n",
    "def aggregate(db, pipeline):\n",
    "    return [doc for doc in db.tweets.aggregate(pipeline)]\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    db = get_db('twitter')\n",
    "    pipeline = make_pipeline()\n",
    "    result = aggregate(db, pipeline)\n",
    "    import pprint\n",
    "    pprint.pprint(result)\n",
    "    assert len(result) == 1\n",
    "    assert result[0][\"followers\"] == 17209\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using unwind\n",
    "\n",
    "For this exercise, let's return to our cities infobox dataset. The question we would like you to answer\n",
    "is as follows: ** Which region or district in India contains the most cities? **(Make sure that the count of\n",
    "cities is stored in a field named 'count'; see the assertions at the end of the script.)\n",
    "\n",
    "As a starting point, use the solution for the example question we looked at -- \"Who includes the most\n",
    "user mentions in their tweets?\"\n",
    "\n",
    "One thing to note about the cities data is that the \"isPartOf\" field contains an array of regions or \n",
    "districts in which a given city is found. See the example document in Instructor Comments below.\n",
    "\n",
    "This is an example document:\n",
    "`\n",
    "{\n",
    "    \"_id\" : ObjectId(\"52fe1d364b5ab856eea75ebc\"),\n",
    "    \"elevation\" : 1855,\n",
    "    \"name\" : \"Kud\",\n",
    "    \"country\" : \"India\",\n",
    "    \"lon\" : 75.28,\n",
    "    \"lat\" : 33.08,\n",
    "    \"isPartOf\" : [\n",
    "        \"Jammu and Kashmir\",\n",
    "        \"Udhampur district\"\n",
    "    ],\n",
    "    \"timeZone\" : [\n",
    "        \"Indian Standard Time\"\n",
    "    ],\n",
    "    \"population\" : 1140\n",
    "}`\n",
    "\n",
    "Tip: Don't forget that we are concerned only with regions in India when you are constructing your pipeline.\n",
    "\n",
    "Please modify only the 'make_pipeline' function so that it creates and returns an aggregation pipeline \n",
    "that can be passed to the MongoDB aggregate function. As in our examples in this lesson, the aggregation \n",
    "pipeline should be a list of one or more dictionary objects. Please review the lesson examples if you \n",
    "are unsure of the syntax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing the first result:\n",
      "{u'_id': u'Uttar Pradesh', u'count': 623}\n"
     ]
    }
   ],
   "source": [
    "def get_db(db_name):\n",
    "    from pymongo import MongoClient\n",
    "    client = MongoClient('localhost:27017')\n",
    "    db = client[db_name]\n",
    "    return db\n",
    "\n",
    "def make_pipeline():\n",
    "    # complete the aggregation pipeline\n",
    "    pipeline = [{'$match' : {'country' : 'India'}},\n",
    "                {'$unwind' : '$isPartOf'},\n",
    "                {'$group' : {'_id': '$isPartOf', 'count' : {'$sum' : 1}}},\n",
    "                {'$sort' : {'count' : -1}},\n",
    "                {'$limit' : 1}]\n",
    "                \n",
    "    return pipeline\n",
    "\n",
    "def aggregate(db, pipeline):\n",
    "    return [doc for doc in db.cities.aggregate(pipeline)]\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    db = get_db('examples')\n",
    "    pipeline = make_pipeline()\n",
    "    result = aggregate(db, pipeline)\n",
    "    print \"Printing the first result:\"\n",
    "    import pprint\n",
    "    pprint.pprint(result[0])\n",
    "    assert result[0][\"_id\"] == \"Uttar Pradesh\"\n",
    "    assert result[0][\"count\"] == 623"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using push\n",
    "\n",
    "`$push` is similar to `$addToSet`. The difference is that rather than accumulating only unique values \n",
    "it aggregates all values into an array.\n",
    "\n",
    "Using an aggregation query, count the number of tweets for each user. In the same `$group` stage, \n",
    "use `$push` to accumulate all the tweet texts for each user. Limit your output to the 5 users\n",
    "with the most tweets. \n",
    "Your result documents should include only the fields:\n",
    "\n",
    "`\"_id\" (screen name of user), \n",
    "\"count\" (number of tweets found for the user),\n",
    "\"tweet_texts\" (a list of the tweet texts found for the user).  \n",
    "` \n",
    "\n",
    "Please modify only the 'make_pipeline' function so that it creates and returns an aggregation \n",
    "pipeline that can be passed to the MongoDB aggregate function. As in our examples in this lesson, \n",
    "the aggregation pipeline should be a list of one or more dictionary objects. \n",
    "Please review the lesson examples if you are unsure of the syntax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-fd171ab39996>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"count\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"count\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0msample_tweet_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mu'Take my money! #liesguystell http://movie.sras2.ayorganes.com'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tweet_texts\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0msample_tweet_text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def get_db(db_name):\n",
    "    from pymongo import MongoClient\n",
    "    client = MongoClient('localhost:27017')\n",
    "    db = client[db_name]\n",
    "    return db\n",
    "\n",
    "def make_pipeline():\n",
    "    # complete the aggregation pipeline\n",
    "    pipeline = [{'$group' : {'_id' : '$user.screen_name',\n",
    "                            'count' : {'$sum' : 1},\n",
    "                            'tweet_texts' : {'$push' : '$text'}}},\n",
    "                {'$sort' : {'count' : -1}}, \n",
    "                {'$limit' : 5} ]\n",
    "    return pipeline\n",
    "\n",
    "def aggregate(db, pipeline):\n",
    "    #return [doc for doc in db.twitter.aggregate(pipeline)]\n",
    "    return [doc for doc in db.tweets.aggregate(pipeline)]\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    db = get_db('twitter')\n",
    "    pipeline = make_pipeline()\n",
    "    result = aggregate(db, pipeline)\n",
    "    import pprint\n",
    "    #pprint.pprint(result)\n",
    "    assert len(result) == 5\n",
    "    assert result[0][\"count\"] > result[4][\"count\"]\n",
    "    sample_tweet_text = u'Take my money! #liesguystell http://movie.sras2.ayorganes.com'\n",
    "    assert result[4][\"tweet_texts\"][0] == sample_tweet_text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Same operator\n",
    "\n",
    "In an earlier exercise we looked at the cities dataset and asked which region in India contains \n",
    "the most cities. In this exercise, we'd like you to answer a related question regarding regions in \n",
    "India. **What is the average city population for a region in India?** Calculate your answer by first \n",
    "finding the average population of cities in each region and then by calculating the average of the \n",
    "regional averages.\n",
    "\n",
    "Hint: If you want to accumulate using values from all input documents to a group stage, you may use \n",
    "a constant as the value of the \"_id\" field. For example, \n",
    "    `{ \"$group\" : {\"_id\" : \"India Regional City Population Average\",\n",
    "      ... }`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{u'_id': u'India Regional City Population Average',\n",
      "  u'avg': 202145.09634580722}]\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-aa84dd25e410>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;31m# Your result should be close to the value after the minus sign.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"avg\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m201128.0241546919\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def get_db(db_name):\n",
    "    from pymongo import MongoClient\n",
    "    client = MongoClient('localhost:27017')\n",
    "    db = client[db_name]\n",
    "    return db\n",
    "\n",
    "def make_pipeline():\n",
    "    # complete the aggregation pipeline\n",
    "    pipeline = [{'$match' : {'country' : 'India'}},\n",
    "                {'$unwind' : '$isPartOf'},\n",
    "                {'$group' : {'_id' : '$isPartOf', 'avgRegion' : {'$avg' : '$population'}}},\n",
    "                {'$group' : {'_id' : 'India Regional City Population Average', 'avg' : {'$avg' : '$avgRegion'}}}]\n",
    "    return pipeline\n",
    "\n",
    "def aggregate(db, pipeline):\n",
    "    return [doc for doc in db.cities.aggregate(pipeline)]\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    db = get_db('examples')\n",
    "    pipeline = make_pipeline()\n",
    "    result = aggregate(db, pipeline)\n",
    "    import pprint\n",
    "    pprint.pprint(result)\n",
    "    \n",
    "    assert len(result) == 1\n",
    "    # Your result should be close to the value after the minus sign.\n",
    "    assert abs(result[0][\"avg\"] - 201128.0241546919) < 10 ** -8\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:DAND]",
   "language": "python",
   "name": "conda-env-DAND-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
